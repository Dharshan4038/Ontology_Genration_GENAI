{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1NNAfJ84TAoqPsywoCCZ341mxepwBBfvi",
      "authorship_tag": "ABX9TyO13ImcoCEHkN4hVF4asDzz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharshan4038/Ontology_Genration_GENAI/blob/main/Ontology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWlartmulGe6"
      },
      "outputs": [],
      "source": [
        "# %pip install PyMuPDF easyocr pandas tabula-py langchain langchain-openai openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install PyPDF2==2.10.5"
      ],
      "metadata": {
        "id": "PDPb1wQPlqtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF for PDF handling\n",
        "import easyocr  # EasyOCR for image text extraction\n",
        "import camelot  # Camelot for table extraction\n",
        "import os"
      ],
      "metadata": {
        "id": "fOz8im2Xmi8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import fitz  # PyMuPDF for PDF handling\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove extra newlines, tabs, and multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Strip leading and trailing spaces\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "O2VljrzeqkE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "\n",
        "    # Loop through each page\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "\n",
        "        # Extract text from page\n",
        "        full_text += page.get_text()\n",
        "\n",
        "        # Extract images from the page\n",
        "        image_list = page.get_images(full=True)\n",
        "\n",
        "        for img_index, img in enumerate(image_list):\n",
        "            xref = img[0]  # Get image XREF\n",
        "            base_image = doc.extract_image(xref)  # Extract the image\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            image_ext = base_image[\"ext\"]\n",
        "            image_filename = f\"/content/drive/MyDrive/Ontology/pdf_images/page_{page_num}_img_{img_index}.{image_ext}\"\n",
        "\n",
        "            # Save the image to disk\n",
        "            with open(image_filename, \"wb\") as img_file:\n",
        "                img_file.write(image_bytes)\n",
        "\n",
        "            # Perform OCR on the extracted image\n",
        "            ocr_result = reader.readtext(image_filename, detail=0)\n",
        "            full_text += \"\\n\".join(ocr_result) + \"\\n\"\n",
        "\n",
        "\n",
        "    return full_text\n",
        "\n",
        "pdf_path = \"/content/drive/MyDrive/RAG/test_case.pdf\"\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "pdf_text = clean_text(pdf_text)\n",
        "# print(pdf_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkhHis5hm169",
        "outputId": "9a0fde88-6b9d-43f0-e3eb-51bc6d8c159a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_table(df):\n",
        "    # Clean each column and row by removing unwanted characters\n",
        "    df = df.applymap(lambda x: re.sub(r'\\s+', ' ', str(x)).strip() if isinstance(x, str) else x)\n",
        "    return df"
      ],
      "metadata": {
        "id": "lYPy0BXKrNqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tables_from_pdf(pdf_path):\n",
        "    # Use Camelot to extract tables\n",
        "    tables = camelot.read_pdf(pdf_path, pages=\"all\", flavor='stream')\n",
        "\n",
        "    cleaned_tables = []\n",
        "\n",
        "    # Process and clean each table\n",
        "    for i, table in enumerate(tables):\n",
        "        df = table.df  # Extract table as Pandas DataFrame\n",
        "        cleaned_df = clean_table(df)  # Clean the DataFrame\n",
        "        cleaned_tables.append(cleaned_df)\n",
        "\n",
        "        # Optionally save the cleaned table to CSV\n",
        "        cleaned_df.to_csv(f\"/content/drive/MyDrive/Ontology/tables_csv/cleaned_table_{i}.csv\", index=False)\n",
        "\n",
        "    return cleaned_tables\n",
        "\n",
        "pdf_path = \"/content/drive/MyDrive/RAG/test_case.pdf\"\n",
        "cleaned_tables = extract_tables_from_pdf(pdf_path)\n",
        "\n",
        "# # Display cleaned tables\n",
        "# for i, cleaned_table in enumerate(cleaned_tables):\n",
        "#     print(f\"Cleaned Table {i}:\")\n",
        "#     print(cleaned_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mq3HmS0cn6ah",
        "outputId": "e8a58dc0-5fe8-4737-9775-02e697bc4775"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/camelot/parsers/stream.py:365: UserWarning: No tables found in table area 1\n",
            "  warnings.warn(f\"No tables found in table area {table_idx + 1}\")\n",
            "/usr/local/lib/python3.10/dist-packages/camelot/parsers/stream.py:365: UserWarning: No tables found in table area 2\n",
            "  warnings.warn(f\"No tables found in table area {table_idx + 1}\")\n",
            "<ipython-input-28-05ca7958f328>:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: re.sub(r'\\s+', ' ', str(x)).strip() if isinstance(x, str) else x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = {\n",
        "    \"pdf_text\": pdf_text,\n",
        "    \"tables\": cleaned_tables\n",
        "}\n",
        "\n",
        "# # Print the combined cleaned data\n",
        "# print(\"Extracted Text from PDF:\\n\", combined_data['pdf_text'])\n",
        "# for i, table in enumerate(combined_data['tables']):\n",
        "#     # print(f\"\\nCleaned Table {i}:\\n\", table)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SxKXGsmAoN8R"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Agent to generate Ontology"
      ],
      "metadata": {
        "id": "TACJIRUNt58e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "import os\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
        "\n",
        "\n",
        "# Initialize the OpenAI LLM for Azure OpenAI\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=\"\",\n",
        "    api_key=\"\",\n",
        "    model = \"gpt-35-turbo\",\n",
        "    max_tokens=1000,\n",
        "    azure_deployment=\"GPT-35-TURBO\",\n",
        "    api_version=\"2024-06-01\"\n",
        ")"
      ],
      "metadata": {
        "id": "Ennse_IdsFOq"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a prompt template for generating the ontology template\n",
        "ontology_prompt = PromptTemplate(\n",
        "    input_variables=[\"pdf_text\", \"tables\"],\n",
        "    template=\"\"\"\n",
        "      Based on the following extracted content from the PDF, including tables and images,\n",
        "      identify key entities (classes), relationships, properties, instances. It should contain\n",
        "      only 5 important classes and its properties and relationships, instances.\n",
        "      Then, generate an ontology in RDF/Turtle format.\n",
        "\n",
        "      PDF text: {pdf_text}\n",
        "      Tables: {tables}\n",
        "\n",
        "      Please generate only the ontology template without mapping specific data points. I dont want you to give any explanation\n",
        "      I want only the ontology template.\n",
        "\n",
        "      eg: RDF/Turtle ontology template:\n",
        "      @prefix ex: <http://example.org/ontology#> .\n",
        "        # Classes\n",
        "        ex:TestingTool a rdfs:Class .\n",
        "        ex:Algorithm a rdfs:Class .\n",
        "        ex:Dataset a rdfs:Class .\n",
        "\n",
        "        # Properties\n",
        "        ex:usesDataset a rdf:Property ;\n",
        "            rdfs:domain ex:TestingTool ;\n",
        "            rdfs:range ex:Dataset .\n",
        "\n",
        "        ex:implementsAlgorithm a rdf:Property ;\n",
        "            rdfs:domain ex:TestingTool ;\n",
        "            rdfs:range ex:Algorithm .\n",
        "\n",
        "        # Example Instances\n",
        "        ex:EvoSuite a ex:TestingTool ;\n",
        "            ex:implementsAlgorithm ex:GeneticAlgorithm ;\n",
        "            ex:usesDataset ex:SF100Corpus .\n",
        "\n",
        "        ex:GeneticAlgorithm a ex:Algorithm .\n",
        "\n",
        "        ex:SF100Corpus a ex:Dataset ;\n",
        "            rdfs:label \"SF100 Corpus\" .\n",
        "\n",
        "            \"\"\"\n",
        ")\n",
        "\n",
        "# Create an LLM chain using the prompt and LLM\n",
        "ontology_chain = ontology_prompt | llm"
      ],
      "metadata": {
        "id": "NkDxS1xDxl6i"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run the agent and generate ontology\n",
        "def generate_ontology(cleaned_data):\n",
        "    pdf_text = cleaned_data['pdf_text'][:5000] #Truncate to the first 5000 characters\n",
        "    tables = \"\\n\".join([str(table) for table in cleaned_data['tables'][:5]])  # Convert tables to string and use only the first 5\n",
        "\n",
        "    # Run the RunnableSequence (use invoke, not run)\n",
        "    ontology_template = ontology_chain.invoke({\n",
        "        \"pdf_text\": pdf_text,\n",
        "        \"tables\": tables\n",
        "    })\n",
        "\n",
        "    return ontology_template"
      ],
      "metadata": {
        "id": "hNBkdOOoyJJr"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the cleaned data from the PDF stored in 'combined_data'\n",
        "combined_data = {\n",
        "    \"pdf_text\": pdf_text,        # Cleaned text from PDF\n",
        "    \"tables\": cleaned_tables     # Cleaned tables from the PDF\n",
        "}\n",
        "\n",
        "# Generate the ontology template using Azure OpenAI\n",
        "ontology_template = generate_ontology(combined_data)\n",
        "\n",
        "# Print the generated ontology template\n",
        "print(ontology_template.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwaZQ7j1ySpc",
        "outputId": "edea939d-b73f-4462-8811-c37338eaa64a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@prefix ex: <http://example.org/ontology#> .\n",
            "\n",
            "# Classes\n",
            "ex:Software a rdfs:Class .\n",
            "ex:TestingTool a rdfs:Class .\n",
            "ex:TestSuite a rdfs:Class .\n",
            "ex:Dataset a rdfs:Class .\n",
            "ex:ResearchPaper a rdfs:Class .\n",
            "\n",
            "# Properties\n",
            "ex:implements a rdf:Property ;\n",
            "    rdfs:domain ex:Software ;\n",
            "    rdfs:range ex:TestingTool .\n",
            "\n",
            "ex:hasTestSuite a rdf:Property ;\n",
            "    rdfs:domain ex:Software ;\n",
            "    rdfs:range ex:TestSuite .\n",
            "\n",
            "ex:usesDataset a rdf:Property ;\n",
            "    rdfs:domain ex:TestingTool ;\n",
            "    rdfs:range ex:Dataset .\n",
            "\n",
            "ex:hasResearchPaper a rdf:Property ;\n",
            "    rdfs:domain ex:Software ;\n",
            "    rdfs:range ex:ResearchPaper .\n",
            "\n",
            "# Example Instances\n",
            "ex:SoftwareTool1 a ex:Software ;\n",
            "    ex:implements ex:TestingTool1 ;\n",
            "    ex:hasTestSuite ex:TestSuite1 ;\n",
            "    ex:usesDataset ex:Dataset1 ;\n",
            "    ex:hasResearchPaper ex:ResearchPaper1 .\n",
            "\n",
            "ex:TestingTool1 a ex:TestingTool .\n",
            "\n",
            "ex:TestSuite1 a ex:TestSuite .\n",
            "\n",
            "ex:Dataset1 a ex:Dataset .\n",
            "\n",
            "ex:ResearchPaper1 a ex:ResearchPaper .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the generated ontology to a .ttl file\n",
        "with open(\"/content/drive/MyDrive/Ontology/Ontology_Template/ontology_template.ttl\", \"w\") as f:\n",
        "    f.write(ontology_template.content)"
      ],
      "metadata": {
        "id": "FjMfdU_RyZ6S"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mIhtowG346wD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}